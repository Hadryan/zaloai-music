{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import os, sys\n",
    "import glob\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "scoring = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# making validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train  = pd.read_csv(\"train_ori.csv\",header=None,names=[\"file\",'class']).set_index(\"file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "class_files = {}\n",
    "for i in range(1,11,1):\n",
    "    indexes = df_train[(df_train['class']==i)].index\n",
    "    class_files[i] = np.random.choice(indexes,int(0.15*len(indexes)) ,replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Ensemble Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_label(feature=\"top\",dataset = \"train\"):\n",
    "    print(feature)\n",
    "    dfs=[]\n",
    "    for key in sorted(select_features[feature].keys()):\n",
    "        df_this = pd.read_csv(select_features[feature][key] % (dataset)).set_index(\"Id\").sort_index() #.astype('category')\n",
    "       \n",
    "        columns = [col+\"_%s\" % (key) for col in df_this.columns] \n",
    "        df_this.columns = columns\n",
    "        \n",
    "        \n",
    "        #columns = [col for col in columns  if int(col.split(\"_\")[-2]) in [0,1,2,3,4]]\n",
    "        \n",
    "        dfs.append(df_this[columns]) \n",
    "    if dataset=='test':\n",
    "        df_f_l = pd.concat(dfs,axis=1)\n",
    "        df_f_l[\"class\"] = -1\n",
    "    else:\n",
    "        dfs.append(df[dataset])\n",
    "        df_f_l = pd.concat(dfs,axis=1)\n",
    "        \n",
    "    return df_f_l.iloc[:,:-1], df_f_l.iloc[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_features = {\n",
    "                   \"raw\":{  \"model1\":\"features_raw_fea_S_%s_1.csv\",\n",
    "                            \"model2\":\"features_raw_fea_S_%s_2.csv\",\n",
    "                            \"model3\":\"features_raw_fea_S_%s_3.csv\",\n",
    "                            \"model7\":\"features_raw_fea_S_%s_7.csv\",\n",
    "                         }\n",
    "                  }\n",
    "\n",
    "df = {\n",
    "    \"train\":pd.read_csv(\"train.csv\",header=None,names=[\"Id\",'class']).set_index(\"Id\").sort_index(),\n",
    "    \"test\":pd.read_csv(\"test.csv\",header=None,names=['Id']).set_index(\"Id\").sort_index(),\n",
    "    \"val\": pd.DataFrame([[f,key] for key in class_files for f in class_files[key]],columns=['Id',\"class\"]).set_index(\"Id\").sort_index(),\n",
    "    \"chaval\":pd.read_csv(\"chaval.csv\",header=None,names=[\"Id\",'class']).set_index(\"Id\").sort_index(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "\n",
    "from scipy.stats import uniform\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import GPy\n",
    "import GPyOpt\n",
    "\n",
    "from GPyOpt.methods import BayesianOptimization\n",
    "\n",
    "# Load the diabetes dataset (for regression)\n",
    "X,y = feature_label(feature=\"raw\",dataset = \"val\")\n",
    "\n",
    "# Instantiate an XGBRegressor with default hyperparameter settings\n",
    "clf = XGBClassifier()\n",
    "\n",
    "bds = [{'name': 'learning_rate', 'type': 'continuous', 'domain': (0.0001, 0.09)},\n",
    "       {'name': 'n_estimators', 'type': 'discrete', 'domain': (500, 1000)},\n",
    "       {\"name\": \"max_depth\", 'type':'discrete', 'domain': (3, 10)},\n",
    "        {'name': 'min_child_weight', 'type': 'discrete', 'domain': (1, 5)},\n",
    "         {'name': 'reg_alpha', 'type': 'continuous', 'domain': (0, 0.05)},\n",
    "         {'name': 'reg_lambda', 'type': 'continuous', 'domain': (0.1, 1)},\n",
    "         {'name': 'subsample', 'type': 'continuous', 'domain': (0.1, 0.6)},\n",
    "         {'name': 'colsample_bytree', 'type': 'continuous', 'domain': (0.1, 0.6)},\n",
    "        ]\n",
    "\n",
    "# Optimization objective \n",
    "def cv_score(parameters):\n",
    "    parameters = parameters[0]\n",
    "    score = cross_val_score(\n",
    "                    XGBClassifier(learning_rate=parameters[0],\\\n",
    "                        n_estimators=int(parameters[1]),\\\n",
    "                        max_depth=int(parameters[2]),\\\n",
    "                        min_child_weight=int(parameters[3]),\\\n",
    "                        reg_alpha = parameters[4],\\\n",
    "                        reg_lambda = parameters[5],\\\n",
    "                        subsample = parameters[6],\\\n",
    "                        colsample_bytree = parameters[7],\\\n",
    "                        n_jobs=5,\\\n",
    "                        objective= \"multi:softprob\",\\\n",
    "                        colsample_bylevel = 1,\\\n",
    "                        booster=\"gbtree\",\\\n",
    "                        scale_pos_weight = 1,\\\n",
    "                        gamma = 0,\\\n",
    "                       ), \n",
    "                X, y, scoring=\"accuracy\", cv=StratifiedKFold(n_splits=5, shuffle=True,random_state=100),n_jobs=10).mean()\n",
    "    score = np.array(score)\n",
    "    return score\n",
    "\n",
    "optimizer = BayesianOptimization(f=cv_score, \n",
    "                                 domain=bds,\n",
    "                                 model_type='GP',\n",
    "                                 acquisition_type ='EI',\n",
    "                                 acquisition_jitter = 0.05,\n",
    "                                 exact_feval=True, \n",
    "                                 maximize=True)\n",
    "\n",
    "# Only 20 iterations because we have 5 initial random points\n",
    "optimizer.run_optimization(max_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.80457988],\n",
       "       [-0.79552019],\n",
       "       [-0.79549461],\n",
       "       [-0.79547003],\n",
       "       [-0.79440016]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.Y[np.argsort(optimizer.Y,axis=0).reshape(-1)][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.39930163e-02, 5.00000000e+02, 1.00000000e+01, 1.00000000e+00,\n",
       "        3.33308086e-02, 2.42777678e-01, 2.63011921e-01, 1.50900610e-01],\n",
       "       [7.22438374e-03, 1.00000000e+03, 3.00000000e+00, 1.00000000e+00,\n",
       "        4.48052850e-02, 8.78036989e-01, 3.88257479e-01, 3.01249371e-01],\n",
       "       [5.07876924e-02, 5.00000000e+02, 1.00000000e+01, 1.00000000e+00,\n",
       "        4.40209711e-02, 1.94824491e-01, 2.24155843e-01, 1.35345156e-01],\n",
       "       [7.52601074e-02, 5.00000000e+02, 1.00000000e+01, 1.00000000e+00,\n",
       "        3.41071685e-02, 2.75208050e-01, 2.22768460e-01, 1.55850192e-01],\n",
       "       [2.22540150e-02, 5.00000000e+02, 1.00000000e+01, 1.00000000e+00,\n",
       "        1.32233022e-02, 2.69048929e-01, 2.49035228e-01, 1.66581821e-01]])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.X[np.argsort(optimizer.Y,axis=0).reshape(-1)][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array([[5.39930163e-02, 5.00000000e+02, 1.00000000e+01, 1.00000000e+00,\n",
    "        3.33308086e-02, 2.42777678e-01, 2.63011921e-01, 1.50900610e-01],\n",
    "       [7.22438374e-03, 1.00000000e+03, 3.00000000e+00, 1.00000000e+00,\n",
    "        4.48052850e-02, 8.78036989e-01, 3.88257479e-01, 3.01249371e-01],\n",
    "       [5.07876924e-02, 5.00000000e+02, 1.00000000e+01, 1.00000000e+00,\n",
    "        4.40209711e-02, 1.94824491e-01, 2.24155843e-01, 1.35345156e-01],\n",
    "       [7.52601074e-02, 5.00000000e+02, 1.00000000e+01, 1.00000000e+00,\n",
    "        3.41071685e-02, 2.75208050e-01, 2.22768460e-01, 1.55850192e-01],\n",
    "       [2.22540150e-02, 5.00000000e+02, 1.00000000e+01, 1.00000000e+00,\n",
    "        1.32233022e-02, 2.69048929e-01, 2.49035228e-01, 1.66581821e-01]])\n",
    "\n",
    "\n",
    "        \n",
    "array([[-0.80457988],\n",
    "       [-0.79552019],\n",
    "       [-0.79549461],\n",
    "       [-0.79547003],\n",
    "       [-0.79440016]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw\n",
      "GridSearchCV took 36.40 seconds for 200 candidatesparameter settings.\n",
      "0.803129074315515\n",
      "{'reg_lambda': 0.3}\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "X,y = feature_label(feature=\"raw\",dataset = \"val\")\n",
    "\n",
    "clf = XGBClassifier(learning_rate=0.05,\\\n",
    "                    n_estimators=700,\\\n",
    "                    min_child_weight=1,\\\n",
    "                    booster=\"gbtree\",\\\n",
    "                    max_depth=5,\\\n",
    "                    scale_pos_weight = 1,\\\n",
    "                    reg_alpha = 0.001,\\\n",
    "                    reg_lambda = 0.3,\\\n",
    "                    subsample = 0.5,\\\n",
    "                    colsample_bytree = 0.3,\\\n",
    "                    n_jobs=5,\\\n",
    "                    objective= \"multi:softmax\",\n",
    "                    colsample_bylevel = 1\n",
    "                   )\n",
    "\n",
    "param_dist = {  \n",
    "                \"reg_lambda\":[0.01,0.1,0.2,0.3]\n",
    "\n",
    "             }\n",
    "\n",
    "\n",
    "xgb_search = GridSearchCV(clf, param_grid=param_dist,\n",
    "                               n_jobs=5,cv=StratifiedKFold(n_splits=5, shuffle=True,random_state=100))\n",
    "\n",
    "start = time()\n",
    "xgb_search.fit(X, y.values.ravel(),eval_metric='auc')\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidates\"\n",
    "      \"parameter settings.\" % ((time() - start), n_iter_search))\n",
    "\n",
    "print(xgb_search.best_score_ )\n",
    "print(xgb_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model with tune-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw\n",
      "raw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "       colsample_bytree=0.15090061000010793, gamma=0,\n",
       "       learning_rate=0.05399301625109518, max_delta_step=0, max_depth=10,\n",
       "       min_child_weight=1, missing=None, n_estimators=500, n_jobs=5,\n",
       "       nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0.03333080862715069, reg_lambda=0.2427776778906675,\n",
       "       scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=0.26301192055025346)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "X1,y1 = feature_label(feature=\"raw\",dataset = \"val\")\n",
    "X2,y2 = feature_label(feature=\"raw\",dataset = \"train\")\n",
    "X = pd.concat([X1,X2])\n",
    "y = pd.concat([y1,y2])\n",
    "np.random.seed(100)\n",
    "re_sample = {1:2, 2: 1.7, 3:1.7, 4:1.5, 5:1.5, 6:1.55, 7:1.5, 8:0.6, 9:2, 10:2}\n",
    "indexes = []\n",
    "for m_class in re_sample:\n",
    "    index_m_class = y[y['class']==m_class].index\n",
    "    replace = True\n",
    "    if re_sample[m_class]<1:\n",
    "        replace = False\n",
    "    indexes.append(np.random.choice(index_m_class ,\\\n",
    "                                    int(len(index_m_class)*re_sample[m_class]), replace=replace))\n",
    "\n",
    "select = np.concatenate(indexes)\n",
    "\n",
    "X = X.loc[select,:]\n",
    "y = y.loc[select,:]\n",
    "'''\n",
    "clf_xgb = XGBClassifier(learning_rate=0.05,\\\n",
    "                    n_estimators=700,\\\n",
    "                    min_child_weight=1,\\\n",
    "                    booster=\"gbtree\",\\\n",
    "                    max_depth=5,\\\n",
    "                    scale_pos_weight = 1,\\\n",
    "                    reg_alpha = 0.001,\\\n",
    "                    reg_lambda = 0.3,\\\n",
    "                    subsample = 0.5,\\\n",
    "                    colsample_bytree = 0.3,\\\n",
    "                    n_jobs=5,\\\n",
    "                    objective= \"multi:softmax\",\n",
    "                    colsample_bylevel = 1\n",
    "                   )\n",
    "'''\n",
    "parameters = optimizer.X[np.argsort(optimizer.Y,axis=0).reshape(-1)][0]\n",
    "clf_xgb = XGBClassifier(learning_rate=parameters[0],\\\n",
    "                        n_estimators=int(parameters[1]),\\\n",
    "                        max_depth=int(parameters[2]),\\\n",
    "                        min_child_weight=int(parameters[3]),\\\n",
    "                        reg_alpha = parameters[4],\\\n",
    "                        reg_lambda = parameters[5],\\\n",
    "                        subsample = parameters[6],\\\n",
    "                        colsample_bytree = parameters[7],\\\n",
    "                        n_jobs=5,\\\n",
    "                        objective= \"multi:softprob\",\\\n",
    "                        colsample_bylevel = 1,\\\n",
    "                        booster=\"dart\",\\\n",
    "                        scale_pos_weight = 1,\\\n",
    "                        gamma = 0,\\\n",
    "                       )\n",
    "\n",
    "clf_xgb.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix: \n",
      "[[  72    0    0    0    0    0    0    0    0    0]\n",
      " [   0  755    1    0    0    0    0    2    0    0]\n",
      " [   0    0  888    0    0    0    0    1    0    0]\n",
      " [   0    0    0  553    0    0    0    0    0    0]\n",
      " [   0    0    0    0  588    0    0    0    0    0]\n",
      " [   0    0    0    0    0  576    0    0    0    0]\n",
      " [   0    0    0    0    0    0  416    2    0    0]\n",
      " [   0    2    3    0    0    0    0 1546    0    0]\n",
      " [   0    0    0    0    0    0    0    0  124    0]\n",
      " [   0    0    0    0    0    0    0    0    0  186]]\n",
      "('accuracy_score:', 0.9980752405949256)\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_xgb.predict(X)\n",
    "y_true = y.values.ravel()\n",
    "print(\"confusion_matrix: \")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(\"accuracy_score:\",accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My validation data set < download from the internet>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw\n",
      "confusion_matrix: \n",
      "[[ 10   1  11   0   0   6   0  16   0   0]\n",
      " [  0  16   3   0   0   2   0   4   0   0]\n",
      " [  0   0   5   0   3   0   0  34   0   0]\n",
      " [  0   0   0  31   0   0   0   0   0   0]\n",
      " [  4   0   1   0  38   0   1   1   0   0]\n",
      " [  0   2   0   0   0  43   0   7   0   1]\n",
      " [  0   1   1   0   2   0  22  55   0   0]\n",
      " [  0   2  13   0   0   5   0 123   1   0]\n",
      " [  0   0   2   8   0   6   0  35 141   5]\n",
      " [  0   0   0   0   0   0   1   4   0  38]]\n",
      "('accuracy_score:', 0.6624113475177305)\n"
     ]
    }
   ],
   "source": [
    "X,y = feature_label(feature=\"raw\",dataset = \"chaval\")\n",
    "y_pred = clf_xgb.predict(X)\n",
    "y_true = y.values.ravel()\n",
    "print(\"confusion_matrix: \")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(\"accuracy_score:\",accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST is to submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw\n"
     ]
    }
   ],
   "source": [
    "X_test,_ = feature_label(feature=\"raw\",dataset = \"test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = pd.DataFrame({\"Id\":X_test.index.values,\"Genre\":clf_xgb.predict(X_test)}).set_index(\"Id\").reset_index()\n",
    "df_submit.to_csv(\"xgb_submission.csv\",header=True,index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb_search.sav']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(clf_xgb, \"xgb_search.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw\n",
      "GridSearchCV took 2233.29 seconds for 200 candidates parameter settings.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "X,y = feature_label(feature=\"raw\",dataset = \"val\")\n",
    "'''\n",
    "X2,y2 = feature_label(feature=\"raw\",dataset = \"train\")\n",
    "X = pd.concat([X1,X2])\n",
    "y = pd.concat([y1,y2])\n",
    "'''\n",
    "clf = GradientBoostingClassifier(n_estimators=200,\\\n",
    "                                 min_samples_leaf=2,\\\n",
    "                                 learning_rate = 0.01,\\\n",
    "                                 max_features=\"auto\",\\\n",
    "                                 max_depth=7,\\\n",
    "                                 subsample = 0.3)\n",
    "\n",
    "\n",
    "param_dist = { \n",
    "              'n_estimators': [400,500,600,700],\\\n",
    "              'max_depth':[5,6,7,8,9,10,11,12]\n",
    "              }\n",
    "\n",
    "n_iter_search = 200 #n_iter=n_iter_search,\n",
    "grab_search = GridSearchCV(clf, param_grid=param_dist,\n",
    "                              n_jobs=5,cv=StratifiedKFold(n_splits=5, shuffle=True,random_state=7))\n",
    "\n",
    "start = time()\n",
    "grab_search.fit(X, y.values.ravel())\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8005215123859192\n",
      "{'n_estimators': 400, 'max_depth': 6}\n"
     ]
    }
   ],
   "source": [
    "print(grab_search.best_score_ )\n",
    "print(grab_search.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model with tune-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw\n",
      "raw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.01, loss='deviance', max_depth=6,\n",
       "              max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=2, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=400,\n",
       "              presort='auto', random_state=None, subsample=0.3, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "X1,y1 = feature_label(feature=\"raw\",dataset = \"val\")\n",
    "X2,y2 = feature_label(feature=\"raw\",dataset = \"train\")\n",
    "X = pd.concat([X1,X2])\n",
    "y = pd.concat([y1,y2])\n",
    "# down sampling at class 8\n",
    "np.random.seed(100)\n",
    "re_sample = {1:2, 2: 1.7, 3:1.7, 4:1.5, 5:1.5, 6:1.55, 7:1.5, 8:0.6, 9:2, 10:2}\n",
    "indexes = []\n",
    "for m_class in re_sample:\n",
    "    index_m_class = y[y['class']==m_class].index\n",
    "    replace = True\n",
    "    if re_sample[m_class]<1:\n",
    "        replace = False\n",
    "    indexes.append(np.random.choice(index_m_class , int(len(index_m_class)*re_sample[m_class]), replace=replace))\n",
    "\n",
    "select = np.concatenate(indexes)\n",
    "\n",
    "X = X.loc[select,:]\n",
    "y = y.loc[select,:]\n",
    "\n",
    "\n",
    "clf_grab = GradientBoostingClassifier(n_estimators=400,\\\n",
    "                                 min_samples_leaf=2,\\\n",
    "                                 learning_rate = 0.01,\\\n",
    "                                 max_features=\"auto\",\\\n",
    "                                 max_depth=6,\\\n",
    "                                 subsample = 0.3)\n",
    "\n",
    "\n",
    "clf_grab.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  72,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,  750,    2,    0,    0,    0,    0,    6,    0,    0],\n",
       "       [   0,    0,  883,    0,    0,    0,    0,    6,    0,    0],\n",
       "       [   0,    0,    0,  553,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,  588,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,  576,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    1,    0,    0,  414,    3,    0,    0],\n",
       "       [   0,    5,    4,    0,    0,    0,    2, 1540,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,  124,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,  186]])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf_grab.predict(X)\n",
    "y_true = y.values.ravel()\n",
    "confusion_matrix(y_true, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994925634295713\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My validation data set < download from the internet>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw\n",
      "confusion_matrix: \n",
      "[[ 10   0  12   0   0   4   1  17   0   0]\n",
      " [  0  16   4   1   0   0   1   3   0   0]\n",
      " [  0   0   6   0   3   0   0  33   0   0]\n",
      " [  0   0   0  31   0   0   0   0   0   0]\n",
      " [  1   2   1   0  35   0   2   4   0   0]\n",
      " [  0   1   0   0   0  43   0   9   0   0]\n",
      " [  0   3   2   0   1   0  25  50   0   0]\n",
      " [  0   1  15   0   0   2   1 125   0   0]\n",
      " [  0   3   4   9   0   4   3  34 137   3]\n",
      " [  0   0   0   0   0   0   1   4   0  38]]\n",
      "('accuracy_score:', 0.6609929078014184)\n"
     ]
    }
   ],
   "source": [
    "X,y = feature_label(feature=\"raw\",dataset = \"chaval\")\n",
    "y_pred = clf_grab.predict(X)\n",
    "y_true = y.values.ravel()\n",
    "print(\"confusion_matrix: \")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(\"accuracy_score:\",accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST is to submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw\n"
     ]
    }
   ],
   "source": [
    "X_test,_ = feature_label(feature=\"raw\",dataset = \"test\")\n",
    "\n",
    "\n",
    "df_submit = pd.DataFrame({\"Id\":X_test.index.values,\"Genre\":clf_grab.predict(X_test)}).set_index(\"Id\").reset_index()\n",
    "df_submit.to_csv(\"grab_submission.csv\",header=True,index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb_search.sav']"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(clf_grab, \"grab_search.sav\")\n",
    "joblib.dump(clf_xgb, \"xgb_search.sav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load(\"xgb_search.sav\")\n",
    "\n",
    "X_test,_ = feature_label(feature=\"raw\",dataset = \"test\")\n",
    "\n",
    "df_submit = pd.DataFrame({\"Id\":X_test.index.values,\"Genre\":model.predict(X_test)}).set_index(\"Id\").reset_index()\n",
    "df_submit.to_csv(\"submission.csv\",header=True,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"xgb_search.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.2687558325056498, gamma=0,\n",
       "       learning_rate=0.005966833485049597, max_delta_step=0, max_depth=10,\n",
       "       min_child_weight=1, missing=nan, n_estimators=500, n_jobs=5,\n",
       "       nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0.05, reg_lambda=0.29025943448521924, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=0.5949681248740692)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
